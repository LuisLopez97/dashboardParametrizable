{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer XML (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "xtree = et.parse(\"tweets_es_interTASS.xml\")\n",
    "xroot = xtree.getroot()\n",
    "\n",
    "df_cols = [\"tweetid\", \"user\", \"content\", \"date\", \"lang\", \"sentiment\"]\n",
    "rows = []\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in xroot: \n",
    "    t_id = node.find(\"tweetid\").text\n",
    "    t_user = node.find(\"user\").text\n",
    "    t_content = node.find(\"content\").text\n",
    "    t_date = node.find(\"date\").text\n",
    "    t_lang = node.find(\"lang\").text\n",
    "    t_sentiment = node.find(\"./sentiment/polarity/value\").text\n",
    "    \n",
    "    rows.append({\"tweetid\": t_id, \"user\":t_user, \"content\": t_content, \"date\": t_date, \"lang\": t_lang, \"sentiment\": t_sentiment})\n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(\"tweets_TAAS.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "def parse_XML(xml_file, df_cols): \n",
    "    \"\"\"Parse the input XML file and store the result in a pandas \n",
    "    DataFrame with the given columns. \n",
    "    \n",
    "    The first element of df_cols is supposed to be the identifier \n",
    "    variable, which is an attribute of each node element in the \n",
    "    XML data; other features will be parsed from the text content \n",
    "    of each sub-element. \n",
    "    \"\"\"\n",
    "    \n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot()\n",
    "    rows = []\n",
    "    \n",
    "    for node in xroot: \n",
    "        res = []\n",
    "        for el in df_cols: \n",
    "            if node is not None and node.find(el) is not None:\n",
    "                if el == df_cols[-1]:\n",
    "                    res.append(node.find(\"./sentiment/polarity/value\").text)\n",
    "                else:\n",
    "                    res.append(node.find(el).text)\n",
    "            else: \n",
    "                res.append(None)\n",
    "        rows.append({df_cols[i]: res[i] \n",
    "                     for i, _ in enumerate(df_cols)})\n",
    "    \n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = [\"tweetid\", \"user\", \"content\", \"date\", \"lang\", \"sentiment\"]\n",
    "out_df = parse_XML(\"intertass-PE-test.xml\", df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out_df.rename(columns = {\"sentiments\": \"sentiment\"}, inplace =True)\n",
    "#out_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769690830114357248</td>\n",
       "      <td>744639307906953216</td>\n",
       "      <td>@MundonickLA @mgabrieladfc siempre hermosa mar...</td>\n",
       "      <td>Sun Aug 28 00:19:28 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771077379531821057</td>\n",
       "      <td>713834336</td>\n",
       "      <td>El sábado me dijeron \"yo te he visto antes, pe...</td>\n",
       "      <td>Wed Aug 31 20:09:07 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>772489016352669701</td>\n",
       "      <td>53311422</td>\n",
       "      <td>Sabes que no tendrás un buen día cuando lo pri...</td>\n",
       "      <td>Sun Sep 04 17:38:28 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>771317218634149888</td>\n",
       "      <td>599653674</td>\n",
       "      <td>En situaciones en las que no sepas que hacer, ...</td>\n",
       "      <td>Thu Sep 01 12:02:09 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>771316436107014144</td>\n",
       "      <td>599653674</td>\n",
       "      <td>El Universo es infinito y como tal quiere que ...</td>\n",
       "      <td>Thu Sep 01 11:59:03 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>771720050017460225</td>\n",
       "      <td>1489810838</td>\n",
       "      <td>Cusco again Días felices #AmoCusco #Urubamba #...</td>\n",
       "      <td>Fri Sep 02 14:42:52 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>771519053211004929</td>\n",
       "      <td>783350538</td>\n",
       "      <td>En el examen de geometría me estoy esforzando ...</td>\n",
       "      <td>Fri Sep 02 01:24:11 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>772626202238578688</td>\n",
       "      <td>91282238</td>\n",
       "      <td>Los putos polos esos que se cruzan en el pecho...</td>\n",
       "      <td>Mon Sep 05 02:43:35 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>772619014820560896</td>\n",
       "      <td>1694172402</td>\n",
       "      <td>@Trovack @iEnterate vamos por buen camino</td>\n",
       "      <td>Mon Sep 05 02:15:02 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>772993402791202816</td>\n",
       "      <td>2393444238</td>\n",
       "      <td>#HaceTiempoYoNo Tengo un novio formal</td>\n",
       "      <td>Tue Sep 06 03:02:43 +0000 2016</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid                user  \\\n",
       "0  769690830114357248  744639307906953216   \n",
       "1  771077379531821057           713834336   \n",
       "2  772489016352669701            53311422   \n",
       "3  771317218634149888           599653674   \n",
       "4  771316436107014144           599653674   \n",
       "5  771720050017460225          1489810838   \n",
       "6  771519053211004929           783350538   \n",
       "7  772626202238578688            91282238   \n",
       "8  772619014820560896          1694172402   \n",
       "9  772993402791202816          2393444238   \n",
       "\n",
       "                                             content  \\\n",
       "0  @MundonickLA @mgabrieladfc siempre hermosa mar...   \n",
       "1  El sábado me dijeron \"yo te he visto antes, pe...   \n",
       "2  Sabes que no tendrás un buen día cuando lo pri...   \n",
       "3  En situaciones en las que no sepas que hacer, ...   \n",
       "4  El Universo es infinito y como tal quiere que ...   \n",
       "5  Cusco again Días felices #AmoCusco #Urubamba #...   \n",
       "6  En el examen de geometría me estoy esforzando ...   \n",
       "7  Los putos polos esos que se cruzan en el pecho...   \n",
       "8          @Trovack @iEnterate vamos por buen camino   \n",
       "9              #HaceTiempoYoNo Tengo un novio formal   \n",
       "\n",
       "                             date lang  sentiment  \n",
       "0  Sun Aug 28 00:19:28 +0000 2016   es        NaN  \n",
       "1  Wed Aug 31 20:09:07 +0000 2016   es        NaN  \n",
       "2  Sun Sep 04 17:38:28 +0000 2016   es        NaN  \n",
       "3  Thu Sep 01 12:02:09 +0000 2016   es        NaN  \n",
       "4  Thu Sep 01 11:59:03 +0000 2016   es        NaN  \n",
       "5  Fri Sep 02 14:42:52 +0000 2016   es        NaN  \n",
       "6  Fri Sep 02 01:24:11 +0000 2016   es        NaN  \n",
       "7  Mon Sep 05 02:43:35 +0000 2016   es        NaN  \n",
       "8  Mon Sep 05 02:15:02 +0000 2016   es        NaN  \n",
       "9  Tue Sep 06 03:02:43 +0000 2016   es        NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.to_csv(\"tweets_interTAAS_Test_PE.csv\", index = None, header=True)\n",
    "df = pd.read_csv(\"tweets_interTAAS_Test_PE.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7219, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntar los conjuntos de entrenamiento y pruebas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntar los train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_general_df = pd.read_csv(\"tweets_TASS_General.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_es_df = pd.read_csv(\"tweets_interTAAS_Train_ES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_cr_df = pd.read_csv(\"tweets_interTAAS_Train_CR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_pe_df = pd.read_csv(\"tweets_interTAAS_Train_PE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7219, 6)\n",
      "(1008, 6)\n",
      "(800, 6)\n",
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_general_df.shape)\n",
    "print(tweets_intertass_es_df.shape)\n",
    "print(tweets_intertass_cr_df.shape)\n",
    "print(tweets_intertass_pe_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10027, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_es = tweets_general_df.append(tweets_intertass_es_df).append(tweets_intertass_cr_df).append(tweets_intertass_pe_df)\n",
    "tweets_es.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_es.to_csv(\"tweets_es.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntar los test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_es_test_df = pd.read_csv(\"tweets_interTASS_Test_ES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_cr_test_df = pd.read_csv(\"tweets_interTAAS_Test_CR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_pe_test_df = pd.read_csv(\"tweets_interTAAS_Test_PE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1899, 6)\n",
      "(1233, 6)\n",
      "(1428, 6)\n"
     ]
    }
   ],
   "source": [
    "#print(tweets_general_df.shape)\n",
    "print(tweets_intertass_es_test_df.shape)\n",
    "print(tweets_intertass_cr_test_df.shape)\n",
    "print(tweets_intertass_pe_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4560, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_es_test = tweets_intertass_es_test_df.append(tweets_intertass_cr_test_df).append(tweets_intertass_pe_test_df)\n",
    "tweets_es_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweetid', 'user', 'data_lemmatized', 'date', 'lang', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_es_test.rename(columns = {\"content\": \"data_lemmatized\"}, inplace =True)\n",
    "tweets_es_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_es_test.to_csv(\"tweets_es_test.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
