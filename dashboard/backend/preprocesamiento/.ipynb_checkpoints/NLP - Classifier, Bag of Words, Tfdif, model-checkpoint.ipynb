{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyendo un Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df = pd.read_csv(\"data_lemmatized.csv\")\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear conjunto de entrenamiento y pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variables de salida (listas)\n",
    "- **x_train**: conjunto de entrenamiento con todas las columnas excepto la que se quiere predecir ('sentiment'). A esas demás columnas se le conocen como 'features' o 'variables'\n",
    "- **x_test**: conjunto de entrenamiento, solo con la columna que se quiere predecir ('sentiment'). A esa columna se le llama 'labels'\n",
    "- **y_train**: conjunto de prueba, solo con los 'features'\n",
    "- **y_test**: conjunto de prueba, solo con los 'labels'\n",
    "--------------------------------------------------------\n",
    "### parametros\n",
    "- **test_size**: porcentaje en que utilizara el conjunto de entrenamiento en todo el dataset\n",
    "- **random_state**: es la semilla de aleatoridad. Permite revolver las filas y columnas, pero siempre dando el mismo resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['data_lemmatized'], y, test_size = 0.33, random_state = 53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar textos a Vectores de Bag of Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializacion de la clase CountVectorizer\n",
    "Aplica preprocesamiento removiendo stopwords\n",
    "\n",
    ".values.astype('U'):\n",
    "https://stackoverflow.com/questions/39303912/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit y Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de Entrenamiento\n",
    "count_train = count_vectorizer.fit_transform(x_train.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de pruebas\n",
    "count_test = count_vectorizer.transform(x_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aadavantage', 'aadfw', 'aadv', 'aadvantage', 'aal', 'aand', 'aano', 'aas', 'aaso', 'aaus', 'ab', 'aback', 'abandon', 'abandonment', 'abassinet', 'abbreve', 'abc', 'abcdef', 'abcs', 'abduct', 'abilities', 'ability', 'able', 'aboard', 'aboout', 'abound', 'abq', 'abroad', 'absolute']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names()[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyendo un TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar al objeto TfidfVectorizer: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = \"english\", max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar los datos de entrenamiento: tfidf_train \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(x_train.values.astype('U'))\n",
    "\n",
    "# Transformar los datos de prueba: tfidf_test \n",
    "tfidf_test = tfidf_vectorizer.transform(x_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aadavantage', 'aadfw', 'aadv', 'aadvantage', 'aal', 'aand', 'aano', 'aas', 'aaso']\n"
     ]
    }
   ],
   "source": [
    "# Imprimir las primeros 10 características\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.23671055 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Imprimir los primeros 5 vectores de tfidf_train\n",
    "print(tfidf_train.A[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspeccionando los vectores (Bag of Words, Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CountVectorizer DataFrame: count_df\n",
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aa  aadavantage  aadfw  aadv  aadvantage  aal  aand  aano  aas  aaso  ...  \\\n",
      "0  0   0            0      0     0           0    0     0     0    0     ...   \n",
      "1  0   0            0      0     0           0    0     0     0    0     ...   \n",
      "2  0   0            0      0     0           0    0     0     0    0     ...   \n",
      "3  0   0            0      0     0           0    0     0     0    0     ...   \n",
      "4  1   0            0      0     0           0    0     0     0    0     ...   \n",
      "\n",
      "   yyzua  zabsonre  zambia  zero  zip  zipper  zone  zoom  zurich  zurichnew  \n",
      "0  0      0         0       0     0    0       0     0     0       0          \n",
      "1  0      0         0       0     0    0       0     0     0       0          \n",
      "2  0      0         0       0     0    0       0     0     0       0          \n",
      "3  0      0         0       0     0    0       0     0     0       0          \n",
      "4  0      0         0       0     0    0       0     0     0       0          \n",
      "\n",
      "[5 rows x 7513 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the head of count_df\n",
    "print(count_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         aa  aadavantage  aadfw  aadv  aadvantage  aal  aand  aano  aas  aaso  \\\n",
      "0  0.000000  0.0          0.0    0.0   0.0         0.0  0.0   0.0   0.0  0.0    \n",
      "1  0.000000  0.0          0.0    0.0   0.0         0.0  0.0   0.0   0.0  0.0    \n",
      "2  0.000000  0.0          0.0    0.0   0.0         0.0  0.0   0.0   0.0  0.0    \n",
      "3  0.000000  0.0          0.0    0.0   0.0         0.0  0.0   0.0   0.0  0.0    \n",
      "4  0.236711  0.0          0.0    0.0   0.0         0.0  0.0   0.0   0.0  0.0    \n",
      "\n",
      "   ...  yyzua  zabsonre  zambia  zero  zip  zipper  zone  zoom  zurich  \\\n",
      "0  ...  0.0    0.0       0.0     0.0   0.0  0.0     0.0   0.0   0.0      \n",
      "1  ...  0.0    0.0       0.0     0.0   0.0  0.0     0.0   0.0   0.0      \n",
      "2  ...  0.0    0.0       0.0     0.0   0.0  0.0     0.0   0.0   0.0      \n",
      "3  ...  0.0    0.0       0.0     0.0   0.0  0.0     0.0   0.0   0.0      \n",
      "4  ...  0.0    0.0       0.0     0.0   0.0  0.0     0.0   0.0   0.0      \n",
      "\n",
      "   zurichnew  \n",
      "0  0.0        \n",
      "1  0.0        \n",
      "2  0.0        \n",
      "3  0.0        \n",
      "4  0.0        \n",
      "\n",
      "[5 rows x 7513 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check whether the DataFrames are equal\n",
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing a classification model with Scikit-learn (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =  nb_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7495860927152318"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2863,  118,   56],\n",
       "       [ 610,  350,   71],\n",
       "       [ 281,   74,  409]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6908112582781457\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3010   21    6]\n",
      " [ 850  157   24]\n",
      " [ 561   32  171]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix: cm\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the model with Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "alphas = np.arange(start = 0, stop = 1, step = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    # Compute accuracy: score\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.722682119205298\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.7363410596026491\n",
      "\n",
      "Alpha:  0.2\n",
      "Score: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja_000\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:485: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.7373758278145696\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.7313741721854304\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.7259933774834437\n",
      "\n",
      "Alpha:  0.5\n",
      "Score:  0.7175082781456954\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.7117135761589404\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.7067466887417219\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.7009519867549668\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.6959850993377483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha = 0.1 dio los mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
