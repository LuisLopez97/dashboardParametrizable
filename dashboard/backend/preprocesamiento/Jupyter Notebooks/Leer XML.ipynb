{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer XML (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "xtree = et.parse(\"tweets_es_interTASS.xml\")\n",
    "xroot = xtree.getroot()\n",
    "\n",
    "df_cols = [\"tweetid\", \"user\", \"content\", \"date\", \"lang\", \"sentiment\"]\n",
    "rows = []\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in xroot: \n",
    "    t_id = node.find(\"tweetid\").text\n",
    "    t_user = node.find(\"user\").text\n",
    "    t_content = node.find(\"content\").text\n",
    "    t_date = node.find(\"date\").text\n",
    "    t_lang = node.find(\"lang\").text\n",
    "    t_sentiment = node.find(\"./sentiment/polarity/value\").text\n",
    "    \n",
    "    rows.append({\"tweetid\": t_id, \"user\":t_user, \"content\": t_content, \"date\": t_date, \"lang\": t_lang, \"sentiment\": t_sentiment})\n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(\"tweets_TAAS.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "def parse_XML(xml_file, df_cols): \n",
    "    \"\"\"Parse the input XML file and store the result in a pandas \n",
    "    DataFrame with the given columns. \n",
    "    \n",
    "    The first element of df_cols is supposed to be the identifier \n",
    "    variable, which is an attribute of each node element in the \n",
    "    XML data; other features will be parsed from the text content \n",
    "    of each sub-element. \n",
    "    \"\"\"\n",
    "    \n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot()\n",
    "    rows = []\n",
    "    \n",
    "    for node in xroot: \n",
    "        res = []\n",
    "        for el in df_cols: \n",
    "            if node is not None and node.find(el) is not None:\n",
    "                if el == df_cols[-1]:\n",
    "                    res.append(node.find(\"./sentiments/polarity/value\").text)\n",
    "                else:\n",
    "                    res.append(node.find(el).text)\n",
    "            else: \n",
    "                res.append(None)\n",
    "        rows.append({df_cols[i]: res[i] \n",
    "                     for i, _ in enumerate(df_cols)})\n",
    "    \n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = [\"tweetid\", \"user\", \"content\", \"date\", \"lang\", \"sentiments\"]\n",
    "out_df = parse_XML(\"general-test-tagged-3l.xml\", df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.rename(columns = {\"sentiments\": \"sentiment\"}, inplace =True)\n",
    "#out_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>lang</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142378325086715906</td>\n",
       "      <td>jesusmarana</td>\n",
       "      <td>Portada 'Público', viernes. Fabra al banquillo...</td>\n",
       "      <td>2011-12-02T00:03:32</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142379080808013825</td>\n",
       "      <td>EvaORegan</td>\n",
       "      <td>Grande! RT @veronicacalderon \"El periodista es...</td>\n",
       "      <td>2011-12-02T00:06:32</td>\n",
       "      <td>es</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142379173120442368</td>\n",
       "      <td>LosadaPescador</td>\n",
       "      <td>Gonzalo Altozano tras la presentación de su li...</td>\n",
       "      <td>2011-12-02T00:06:55</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142379815708803072</td>\n",
       "      <td>mgilguerrero</td>\n",
       "      <td>Mañana en Gaceta: TVE, la que pagamos tú y yo,...</td>\n",
       "      <td>2011-12-02T00:09:28</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142381190123499520</td>\n",
       "      <td>pedroj_ramirez</td>\n",
       "      <td>Qué envidia “@mfcastineiras: Pedro mañana x la...</td>\n",
       "      <td>2011-12-02T00:14:55</td>\n",
       "      <td>es</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>142382515380961280</td>\n",
       "      <td>mgilguerrero</td>\n",
       "      <td>Más mañana en Gaceta. Amaiur depende de Uxue B...</td>\n",
       "      <td>2011-12-02T00:20:11</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>142382561501511680</td>\n",
       "      <td>SSantiagosegura</td>\n",
       "      <td>Muy buenas noches followercetes, mañana va a s...</td>\n",
       "      <td>2011-12-02T00:20:23</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>142382722910912512</td>\n",
       "      <td>mgilguerrero</td>\n",
       "      <td>Más de mañana en Gaceta. UPyD contará casi seg...</td>\n",
       "      <td>2011-12-02T00:21:01</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>142384554206961664</td>\n",
       "      <td>mariviromero</td>\n",
       "      <td>La felicidad no esta en los grandes anhelos , ...</td>\n",
       "      <td>2011-12-02T00:28:17</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142386873539637248</td>\n",
       "      <td>mgilguerrero</td>\n",
       "      <td>\"Ya lo veremos, ya lo veremos...\" les ha respo...</td>\n",
       "      <td>2011-12-02T00:37:30</td>\n",
       "      <td>es</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweetid             user  \\\n",
       "0  142378325086715906      jesusmarana   \n",
       "1  142379080808013825        EvaORegan   \n",
       "2  142379173120442368   LosadaPescador   \n",
       "3  142379815708803072     mgilguerrero   \n",
       "4  142381190123499520   pedroj_ramirez   \n",
       "5  142382515380961280     mgilguerrero   \n",
       "6  142382561501511680  SSantiagosegura   \n",
       "7  142382722910912512     mgilguerrero   \n",
       "8  142384554206961664     mariviromero   \n",
       "9  142386873539637248     mgilguerrero   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  Portada 'Público', viernes. Fabra al banquillo...  2011-12-02T00:03:32   \n",
       "1  Grande! RT @veronicacalderon \"El periodista es...  2011-12-02T00:06:32   \n",
       "2  Gonzalo Altozano tras la presentación de su li...  2011-12-02T00:06:55   \n",
       "3  Mañana en Gaceta: TVE, la que pagamos tú y yo,...  2011-12-02T00:09:28   \n",
       "4  Qué envidia “@mfcastineiras: Pedro mañana x la...  2011-12-02T00:14:55   \n",
       "5  Más mañana en Gaceta. Amaiur depende de Uxue B...  2011-12-02T00:20:11   \n",
       "6  Muy buenas noches followercetes, mañana va a s...  2011-12-02T00:20:23   \n",
       "7  Más de mañana en Gaceta. UPyD contará casi seg...  2011-12-02T00:21:01   \n",
       "8  La felicidad no esta en los grandes anhelos , ...  2011-12-02T00:28:17   \n",
       "9  \"Ya lo veremos, ya lo veremos...\" les ha respo...  2011-12-02T00:37:30   \n",
       "\n",
       "  lang sentiment  \n",
       "0   es         N  \n",
       "1   es      NONE  \n",
       "2   es         P  \n",
       "3   es         N  \n",
       "4   es      NONE  \n",
       "5   es         N  \n",
       "6   es         P  \n",
       "7   es         P  \n",
       "8   es         P  \n",
       "9   es         N  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.to_csv(\"tweets_TASS_General_Development.csv\", index = None, header=True)\n",
    "df = pd.read_csv(\"tweets_TASS_General_Development.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60798, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntar los conjuntos de entrenamiento y pruebas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntar los train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_general_df = pd.read_csv(\"tweets_TASS_General.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_es_df = pd.read_csv(\"tweets_interTAAS_Train_ES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_cr_df = pd.read_csv(\"tweets_interTAAS_Train_CR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_pe_df = pd.read_csv(\"tweets_interTAAS_Train_PE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7219, 6)\n",
      "(1008, 6)\n",
      "(800, 6)\n",
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_general_df.shape)\n",
    "print(tweets_intertass_es_df.shape)\n",
    "print(tweets_intertass_cr_df.shape)\n",
    "print(tweets_intertass_pe_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10027, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_es = tweets_general_df.append(tweets_intertass_es_df).append(tweets_intertass_cr_df).append(tweets_intertass_pe_df)\n",
    "tweets_es.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_es.to_csv(\"tweets_es.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntar los test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_general_test_df = pd.read_csv(\"tweets_TASS_General_Development.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_es_test_df = pd.read_csv(\"tweets_interTASS_Development_ES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_cr_test_df = pd.read_csv(\"tweets_interTASS_Development_CR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_intertass_pe_test_df = pd.read_csv(\"tweets_interTASS_Development_PE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39382, 6)\n",
      "(506, 6)\n",
      "(300, 6)\n",
      "(500, 6)\n"
     ]
    }
   ],
   "source": [
    "print(tweets_general_test_df.shape)\n",
    "print(tweets_intertass_es_test_df.shape)\n",
    "print(tweets_intertass_cr_test_df.shape)\n",
    "print(tweets_intertass_pe_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40688, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_es_test = tweets_general_test_df.append(tweets_intertass_es_test_df).append(tweets_intertass_cr_test_df).append(tweets_intertass_pe_test_df)\n",
    "tweets_es_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweetid', 'user', 'data_lemmatized', 'date', 'lang', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_es_test.rename(columns = {\"content\": \"data_lemmatized\"}, inplace =True)\n",
    "tweets_es_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_es_test.to_csv(\"tweets_es_development.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
